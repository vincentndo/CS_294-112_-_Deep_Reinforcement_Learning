{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TASK = \"Ant-v2\"\n",
    "# TASK = \"HalfCheetah-v2\"\n",
    "# TASK = \"Hopper-v2\"\n",
    "# TASK = \"Humanoid-v2\"\n",
    "# TASK = \"Reacher-v2\"\n",
    "# TASK = \"Walker2d-v2\"\n",
    "\n",
    "TASK_LIST = [\"Ant-v2\", \"HalfCheetah-v2\", \"Hopper-v2\", \"Humanoid-v2\", \"Reacher-v2\", \"Walker2d-v2\"]\n",
    "\n",
    "DIRNAME_experts = \"experts\"\n",
    "DIRNAME_expert_data = \"expert_data\"\n",
    "DIRNAME_MODELS = \"BC_models\"\n",
    "DIRNAME_output = \"output\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2\n",
    "    First, we build, train and save the models for the tasks in TASK_LIST.\n",
    "    Next, we load and test each model.\n",
    "    Last, we collect the results of each model (mean and std of rewards over 20 iterations).\n",
    "    \n",
    "    The models were built and trained already and are located in the directory BC_models. Skip building an training them or delete this directory to build and train the models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model of Ant-v2 exists in the directory BC_models.\n",
      "\n",
      "Model of HalfCheetah-v2 exists in the directory BC_models.\n",
      "\n",
      "Model of Hopper-v2 exists in the directory BC_models.\n",
      "\n",
      "Model of Humanoid-v2 exists in the directory BC_models.\n",
      "\n",
      "Model of Reacher-v2 exists in the directory BC_models.\n",
      "\n",
      "Model of Walker2d-v2 exists in the directory BC_models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_train_save_model(X_train, Y_train, model_path, batch_size=BATCH_SIZE, epochs=EPOCHS):\n",
    "    \n",
    "    print(\"The shapes of training input and output: X:{}, Y:{}\".format(X_train.shape, Y_train.shape))\n",
    "    sample_size = X_train.shape[0]\n",
    "    input_size = X_train.shape[-1]\n",
    "    output_size = Y_train.shape[-1]\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Hidden layer 1: input -> output (64,)\n",
    "    model.add( tf.keras.layers.Dense(64, input_dim=input_size) )\n",
    "    model.add( tf.keras.layers.Activation(\"relu\") )\n",
    "    \n",
    "    # Hidden layer 2: output (64,) -> output (64,)\n",
    "    model.add( tf.keras.layers.Dense(64) )\n",
    "    model.add( tf.keras.layers.Activation(\"relu\") )\n",
    "    \n",
    "    # Hidden layer 3: output (64,) -> output\n",
    "    model.add( tf.keras.layers.Dense(output_size) )\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=\"Adam\")\n",
    "    print(\"Training model ...\")\n",
    "    model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=epochs, verbose=1)\n",
    "    \n",
    "    model_dir = os.path.dirname(model_path)\n",
    "    if not os.path.isdir( model_dir ):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    model.save(model_path)\n",
    "\n",
    "    \n",
    "for task in TASK_LIST:\n",
    "    model_name = \"BC_model_\" + task + \".h5\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Task {}. Behavioral Cloning.\".format(task))\n",
    "        datafile = os.path.join(DIRNAME_expert_data, task + \".pkl\")\n",
    "        \n",
    "        with open(datafile, 'rb') as f:\n",
    "            expert_data = pickle.load(f)\n",
    "\n",
    "        X_train = expert_data[\"observations\"]\n",
    "        Y_train = np.squeeze( expert_data[\"actions\"] )\n",
    "        \n",
    "        build_train_save_model(X_train, Y_train, model_path)\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + task + \" exists in the directory \" + DIRNAME_MODELS + '.')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Ant-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4795.814486983164, 4863.421658116031, 4779.958026567731, 4647.43879367636, 4819.813104734592, 4841.787095732694, 4852.739062724923, 4976.429785899354, 4799.927384369573, 4907.93983233427, 4914.238221893906, 4780.210411179718, 4866.566576606987, 4573.113958238297, 4564.407389902488, 4717.181374821776, 4676.222907900323, 4758.021051189747, 4906.945279666806, 5032.016071399261]\n",
      "mean reward 4803.709623696899\n",
      "std of reward 120.2507277428963\n",
      "\n",
      "Task HalfCheetah-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4133.104862277909, 4129.020679306071, 4069.391487975378, 4218.7422752143675, 4076.2856361007175, 4217.068534230362, 4019.596647069303, 4155.974803586173, 4201.88463813951, 4270.971648088657, 4099.090781731187, 4052.6144517283115, 4093.0334508647866, 4174.477539750896, 4136.909552779033, 3902.5373138062823, 3982.853290441836, 4019.3767046060957, 4066.275178970691, 4064.6922054014385]\n",
      "mean reward 4104.195084103451\n",
      "std of reward 86.8627632844331\n",
      "\n",
      "Task Hopper-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [2519.4992710428837, 2706.908593033306, 2483.08759641278, 1872.7680000547512, 1462.6699409283365, 1807.8025192048485, 1548.9714036954706, 1592.3404880105454, 1655.2037478801712, 2191.56377910502, 1542.5836443581397, 1544.2498086667547, 1352.0030018774478, 1604.299983710557, 1073.8714200671789, 3092.237812077189, 1722.831825958214, 2256.713227855979, 2270.731450504734, 1587.6078520811939]\n",
      "mean reward 1894.397268326275\n",
      "std of reward 503.8442532288752\n",
      "\n",
      "Task Humanoid-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [1038.1452490779363, 4772.893106722063, 709.6547076521362, 1257.3969255200877, 1858.2363971430334, 1638.9117104563659, 1988.6759469023148, 416.83554364789507, 1608.502559223856, 1553.810094736587, 940.3690845647847, 1080.5723874642235, 3095.689331587453, 1543.5836399917514, 880.5100507454017, 829.5299199625539, 521.9844979270218, 1547.676595530259, 1087.5536438656668, 634.3159384399719]\n",
      "mean reward 1450.242366558068\n",
      "std of reward 971.6560239829718\n",
      "\n",
      "Task Reacher-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [-12.410374976515874, -2.6428805999500287, -8.974531152258837, -3.14124383232611, -6.806098618748043, -5.004629756931126, -10.355841342186768, -4.137284447217755, -2.8603957963981648, -5.440213180800891, -5.343348708960874, -4.628833841290053, -19.182953405257962, -3.528189406882632, -9.828637396432807, -6.089759822088588, -4.443777234787445, -9.183385986237312, -7.554695967655654, -6.245918590704162]\n",
      "mean reward -6.890149703181554\n",
      "std of reward 3.8710560201318756\n",
      "\n",
      "Task Walker2d-v2. Behavioral Cloning\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [5607.6974756107675, 5631.426597698008, 5553.459707759309, 5580.856421180987, 5564.998867892043, 5622.286593997182, 5646.315298007976, 5633.921730888699, 5657.380140048451, 5659.437147095375, 5624.814075645203, 5530.105725572707, 5533.203597865472, 5640.163994110931, 5629.178098757509, 5578.088676659018, 5586.978112467802, 5595.779193891538, 5626.665641685602, 5616.32178022112]\n",
      "mean reward 5605.9539438527845\n",
      "std of reward 37.93767830463466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_test_model(task, model_path):\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    envname = task\n",
    "    env = gym.make(envname)\n",
    "    max_steps = env.spec.timestep_limit\n",
    "    num_rollouts = 20\n",
    "    \n",
    "    rewards = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(num_rollouts):\n",
    "        print(\"iter\", i)\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model.predict(obs.reshape(1, -1), verbose=0)\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            if False:\n",
    "                env.render()\n",
    "#             if steps % 100 == 0:\n",
    "#                 print(\"{}/{}\".format(steps, max_steps))\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        rewards.append(total_reward)\n",
    "        \n",
    "    mean_reward, std_reward = np.mean(rewards), np.std(rewards)\n",
    "    print(\"rewards\", rewards)\n",
    "    print(\"mean reward\", mean_reward)\n",
    "    print(\"std of reward\", std_reward)\n",
    "    \n",
    "    ret_dict = {\"rewards\": rewards, \"mean reward\": mean_reward, \"std of reward\": std_reward}\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "for task in TASK_LIST:\n",
    "    model_name = \"BC_model_\" + task + \".h5\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_name)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Task {}. Behavioral Cloning\".format(task))\n",
    "        load_test_model(task, model_path)\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + task + \" doest not exist. Build and train it first.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.3\n",
    "    Task selected: Ant.\n",
    "    Examine the performance over a wide range of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Ant-v2. Building and Training model over 2 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0353\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0115\n",
      "\n",
      "Task Ant-v2. Building and Training model over 4 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0445\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0129\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0093\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0076\n",
      "\n",
      "Task Ant-v2. Building and Training model over 6 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/6\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.0462\n",
      "Epoch 2/6\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0126\n",
      "Epoch 3/6\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0091\n",
      "Epoch 4/6\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0073\n",
      "Epoch 5/6\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0061\n",
      "Epoch 6/6\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0053\n",
      "\n",
      "Task Ant-v2. Building and Training model over 8 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.0368\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0125\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0088\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0070\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0058\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0050\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0043\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0039\n",
      "\n",
      "Task Ant-v2. Building and Training model over 10 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.0510\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0134\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0096\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0078\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0065\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0056\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0049\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0043\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0038\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0034\n",
      "\n",
      "Task Ant-v2. Building and Training model over 12 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.0399\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0120\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0088\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0071\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0060\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0052\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0046\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0040\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0036\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0032\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0029\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0027\n",
      "\n",
      "Task Ant-v2. Building and Training model over 14 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/14\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.0402\n",
      "Epoch 2/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0122\n",
      "Epoch 3/14\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0087\n",
      "Epoch 4/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0070\n",
      "Epoch 5/14\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0059\n",
      "Epoch 6/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0050\n",
      "Epoch 7/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0044\n",
      "Epoch 8/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0039\n",
      "Epoch 9/14\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0034\n",
      "Epoch 10/14\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0031\n",
      "Epoch 11/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0028\n",
      "Epoch 12/14\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0027\n",
      "Epoch 13/14\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0024\n",
      "Epoch 14/14\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0022\n",
      "\n",
      "Task Ant-v2. Building and Training model over 16 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/16\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0371\n",
      "Epoch 2/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0117\n",
      "Epoch 3/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0084\n",
      "Epoch 4/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0067\n",
      "Epoch 5/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0056\n",
      "Epoch 6/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0048\n",
      "Epoch 7/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0042\n",
      "Epoch 8/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0037\n",
      "Epoch 9/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0034\n",
      "Epoch 10/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0031\n",
      "Epoch 11/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0027\n",
      "Epoch 12/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0026\n",
      "Epoch 13/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0024\n",
      "Epoch 14/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0022\n",
      "Epoch 15/16\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 16/16\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0020\n",
      "\n",
      "Task Ant-v2. Building and Training model over 18 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/18\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0410\n",
      "Epoch 2/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0119\n",
      "Epoch 3/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0086\n",
      "Epoch 4/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0070\n",
      "Epoch 5/18\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0060\n",
      "Epoch 6/18\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0052\n",
      "Epoch 7/18\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0046\n",
      "Epoch 8/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0037\n",
      "Epoch 10/18\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0033\n",
      "Epoch 11/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0030\n",
      "Epoch 12/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0027\n",
      "Epoch 13/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0025\n",
      "Epoch 14/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0024\n",
      "Epoch 15/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0022\n",
      "Epoch 16/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0020\n",
      "Epoch 17/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 18/18\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "\n",
      "Task Ant-v2. Building and Training model over 20 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0323\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0113\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0083\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0067\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0056\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0048\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0042\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0037\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0033\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0029\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0027\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0024\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0023\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0021\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0020\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0018\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0017\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0017\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0015\n",
      "\n",
      "Task Ant-v2. Building and Training model over 22 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/22\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.0420\n",
      "Epoch 2/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0122\n",
      "Epoch 3/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0086\n",
      "Epoch 4/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0069\n",
      "Epoch 5/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0058\n",
      "Epoch 6/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0050\n",
      "Epoch 7/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0044\n",
      "Epoch 8/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0039\n",
      "Epoch 9/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0034\n",
      "Epoch 10/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0031\n",
      "Epoch 11/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0029\n",
      "Epoch 12/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0026\n",
      "Epoch 13/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0024\n",
      "Epoch 14/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0022\n",
      "Epoch 15/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0020\n",
      "Epoch 16/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 17/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0018\n",
      "Epoch 18/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0017\n",
      "Epoch 19/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 20/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 21/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0015\n",
      "Epoch 22/22\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0014\n",
      "\n",
      "Task Ant-v2. Building and Training model over 24 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/24\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0372\n",
      "Epoch 2/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0119\n",
      "Epoch 3/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0086\n",
      "Epoch 4/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0069\n",
      "Epoch 5/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0059\n",
      "Epoch 6/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0050\n",
      "Epoch 7/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0044\n",
      "Epoch 8/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0039\n",
      "Epoch 9/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0035\n",
      "Epoch 10/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0032\n",
      "Epoch 11/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0029\n",
      "Epoch 12/24\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0026\n",
      "Epoch 13/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0024\n",
      "Epoch 14/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0023\n",
      "Epoch 15/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0021\n",
      "Epoch 16/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 17/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 18/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0017\n",
      "Epoch 19/24\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 20/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 21/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0015\n",
      "Epoch 22/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0014\n",
      "Epoch 23/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0014\n",
      "Epoch 24/24\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0013\n",
      "\n",
      "Task Ant-v2. Building and Training model over 26 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/26\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0306\n",
      "Epoch 2/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0111\n",
      "Epoch 3/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0078\n",
      "Epoch 4/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0061\n",
      "Epoch 5/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0052\n",
      "Epoch 6/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0044\n",
      "Epoch 7/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0038\n",
      "Epoch 8/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0034\n",
      "Epoch 9/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0031\n",
      "Epoch 10/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0028\n",
      "Epoch 11/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0025\n",
      "Epoch 12/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0024\n",
      "Epoch 13/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0022\n",
      "Epoch 14/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 15/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 16/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0019\n",
      "Epoch 17/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0018\n",
      "Epoch 18/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 19/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 20/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 21/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0015\n",
      "Epoch 22/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 23/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 24/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0014\n",
      "Epoch 25/26\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 26/26\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0013\n",
      "\n",
      "Task Ant-v2. Building and Training model over 28 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/28\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.0460\n",
      "Epoch 2/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0130\n",
      "Epoch 3/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0091\n",
      "Epoch 4/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0073\n",
      "Epoch 5/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0062\n",
      "Epoch 6/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0054\n",
      "Epoch 7/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0048\n",
      "Epoch 8/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0043\n",
      "Epoch 9/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0039\n",
      "Epoch 10/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0035\n",
      "Epoch 11/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0031\n",
      "Epoch 12/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0029\n",
      "Epoch 13/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0026\n",
      "Epoch 14/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0024\n",
      "Epoch 15/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0022\n",
      "Epoch 16/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 17/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0020\n",
      "Epoch 18/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0019\n",
      "Epoch 19/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0018\n",
      "Epoch 20/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0017\n",
      "Epoch 21/28\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0016\n",
      "Epoch 22/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 23/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 24/28\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 25/28\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 26/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 27/28\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 28/28\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0013\n",
      "\n",
      "Task Ant-v2. Building and Training model over 30 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.0422\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0121\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0088\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0071\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0060\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0053\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0046\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0041\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0037\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0033\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0030\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0027\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0025\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0023\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0021\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0020\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0019\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0018\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0017\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0016\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0016\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0015\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0014\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0014\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0013\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0013\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0013\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0012\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0012\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0011\n",
      "\n",
      "Task Ant-v2. Building and Training model over 32 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/32\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0359\n",
      "Epoch 2/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0116\n",
      "Epoch 3/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0083\n",
      "Epoch 4/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 5/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0056\n",
      "Epoch 6/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0049\n",
      "Epoch 7/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0043\n",
      "Epoch 8/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0038\n",
      "Epoch 9/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0034\n",
      "Epoch 10/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0031\n",
      "Epoch 11/32\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0028\n",
      "Epoch 12/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0026\n",
      "Epoch 13/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0024\n",
      "Epoch 14/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0022\n",
      "Epoch 15/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0021\n",
      "Epoch 16/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0020\n",
      "Epoch 17/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0019\n",
      "Epoch 18/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0017\n",
      "Epoch 19/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0017\n",
      "Epoch 20/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0016\n",
      "Epoch 21/32\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0015\n",
      "Epoch 22/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0015\n",
      "Epoch 23/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0015\n",
      "Epoch 24/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 25/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 26/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0013\n",
      "Epoch 27/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 28/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 29/32\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 30/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 31/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 32/32\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "\n",
      "Task Ant-v2. Building and Training model over 34 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/34\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.0489\n",
      "Epoch 2/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0131\n",
      "Epoch 3/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0092\n",
      "Epoch 4/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0073\n",
      "Epoch 5/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0061\n",
      "Epoch 6/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0053\n",
      "Epoch 7/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0047\n",
      "Epoch 8/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0041\n",
      "Epoch 9/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0037\n",
      "Epoch 10/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0033\n",
      "Epoch 11/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0030\n",
      "Epoch 12/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0026\n",
      "Epoch 13/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0025\n",
      "Epoch 14/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0023\n",
      "Epoch 15/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 16/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0020\n",
      "Epoch 17/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0019\n",
      "Epoch 18/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0018\n",
      "Epoch 19/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 20/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 21/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 22/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 23/34\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0014\n",
      "Epoch 24/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 25/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 26/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 27/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 28/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 29/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 30/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 31/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 32/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 33/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 34/34\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "\n",
      "Task Ant-v2. Building and Training model over 36 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/36\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0380\n",
      "Epoch 2/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0117\n",
      "Epoch 3/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0084\n",
      "Epoch 4/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0068\n",
      "Epoch 5/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0058\n",
      "Epoch 6/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0050\n",
      "Epoch 7/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0045\n",
      "Epoch 8/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0040\n",
      "Epoch 9/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0036\n",
      "Epoch 10/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0032\n",
      "Epoch 11/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0029\n",
      "Epoch 12/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0027\n",
      "Epoch 13/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0025\n",
      "Epoch 14/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0023\n",
      "Epoch 15/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0022\n",
      "Epoch 16/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 17/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0019\n",
      "Epoch 18/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0019\n",
      "Epoch 19/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0018\n",
      "Epoch 20/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 21/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 22/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 23/36\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0015\n",
      "Epoch 24/36\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0015\n",
      "Epoch 25/36\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0014\n",
      "Epoch 26/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 27/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 28/36\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0013\n",
      "Epoch 29/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 30/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 31/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 32/36\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0012\n",
      "Epoch 33/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 34/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 35/36\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0011\n",
      "Epoch 36/36\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "\n",
      "Task Ant-v2. Building and Training model over 38 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/38\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.0348\n",
      "Epoch 2/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0120\n",
      "Epoch 3/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0088\n",
      "Epoch 4/38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0070\n",
      "Epoch 5/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0060\n",
      "Epoch 6/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0051\n",
      "Epoch 7/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0045\n",
      "Epoch 8/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0040\n",
      "Epoch 9/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0035\n",
      "Epoch 10/38\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0031\n",
      "Epoch 11/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0028\n",
      "Epoch 12/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0026\n",
      "Epoch 13/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0024\n",
      "Epoch 14/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0022\n",
      "Epoch 15/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 16/38\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0020\n",
      "Epoch 17/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0018\n",
      "Epoch 18/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0017\n",
      "Epoch 19/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 20/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0016\n",
      "Epoch 21/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0016\n",
      "Epoch 22/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0015\n",
      "Epoch 23/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 24/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 25/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 26/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0013\n",
      "Epoch 27/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0013\n",
      "Epoch 28/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 29/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 30/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 31/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0012\n",
      "Epoch 32/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 33/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0011\n",
      "Epoch 34/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0011\n",
      "Epoch 35/38\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 36/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0011\n",
      "Epoch 37/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0010\n",
      "Epoch 38/38\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 9.9715e-04\n",
      "\n",
      "Task Ant-v2. Building and Training model over 40 epochs:\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/40\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.0395\n",
      "Epoch 2/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0120\n",
      "Epoch 3/40\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0086\n",
      "Epoch 4/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 5/40\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0059\n",
      "Epoch 6/40\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0051\n",
      "Epoch 7/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0044\n",
      "Epoch 8/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0039\n",
      "Epoch 9/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0035\n",
      "Epoch 10/40\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0032\n",
      "Epoch 11/40\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0029\n",
      "Epoch 12/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0026\n",
      "Epoch 13/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0024\n",
      "Epoch 14/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0022\n",
      "Epoch 15/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 16/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0020\n",
      "Epoch 17/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0019\n",
      "Epoch 18/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0018\n",
      "Epoch 19/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 20/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0017\n",
      "Epoch 21/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0016\n",
      "Epoch 22/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 23/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0015\n",
      "Epoch 24/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0014\n",
      "Epoch 25/40\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0014\n",
      "Epoch 26/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 27/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 28/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 29/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0013\n",
      "Epoch 30/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 31/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 32/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 33/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0012\n",
      "Epoch 34/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 35/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 36/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0011\n",
      "Epoch 37/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0010\n",
      "Epoch 38/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0010\n",
      "Epoch 39/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0010\n",
      "Epoch 40/40\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 9.9151e-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TASK_multi_epoch = \"Ant-v2\"\n",
    "epoch_range = range(2, 41, 2)\n",
    "\n",
    "for epoch_num in epoch_range:\n",
    "    model_name = \"BC_model_\" + TASK_multi_epoch + \"_epochs_\" + str(epoch_num) + \".h5\"\n",
    "    model_dir = TASK_multi_epoch + \"_epochs\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_dir, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Task {}. Building and Training model over {} epochs:\".format(TASK_multi_epoch, epoch_num))\n",
    "        datafile = os.path.join(DIRNAME_expert_data, TASK_multi_epoch + \".pkl\")\n",
    "        \n",
    "        with open(datafile, 'rb') as f:\n",
    "            expert_data = pickle.load(f)\n",
    "\n",
    "        X_train = expert_data[\"observations\"]\n",
    "        Y_train = np.squeeze( expert_data[\"actions\"] )\n",
    "        build_train_save_model(X_train, Y_train, model_path, epochs=epoch_num)\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + TASK_multi_epoch + \", trained over \" + str(epoch_num)\n",
    "              + \" epoches, exists in the directory \" + os.path.join(DIRNAME_MODELS, model_dir) + '.')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Ant-v2. Model trained over 2 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [813.7256841536159, 923.4632458325817, 1079.7848961710558, 1122.3512968119876, 1005.8180301863201, 1091.199850741454, 1130.7556781295552, 1064.6387332827771, 1093.2898398246741, 983.6434291618173, 1073.5246836727897, 930.9186782595432, 971.1402154378584, 1087.526620453397, 1075.098440984211, 1170.3456074416733, 974.2041853024716, 924.6694943556361, 973.4304931017753, 1038.0718624825884]\n",
      "mean reward 1026.3800482893892\n",
      "std of reward 86.13801542553337\n",
      "\n",
      "Task Ant-v2. Model trained over 4 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [1157.7270476134672, 2403.5100042115423, 1453.538309104256, 1341.691964665653, 1513.8784458530097, 1014.3472569766482, 1279.051398976397, 1123.81984593322, 1844.0238524047081, 1005.1812283667706, 864.0552220654457, 2125.3756553909043, 1431.5875576021037, 1297.7101002499494, 1251.89876030823, 2089.646212237788, 2730.0044499864844, 1683.5520610876022, 1077.242655465882, 1008.2703141416608]\n",
      "mean reward 1484.8056171320861\n",
      "std of reward 498.15388372395375\n",
      "\n",
      "Task Ant-v2. Model trained over 6 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4154.436747235684, 4269.486203978692, 4065.182010227985, 3551.651578529542, 4439.089518666231, 4128.678140885685, 4466.138654500091, 4185.240212482957, 4121.722762178905, 641.1218219720425, 4348.104742000755, 1096.2235952881244, 4391.164716502511, 4046.7155439852345, 2773.268333793111, 4166.984410429484, 4226.696943106943, 4193.038266547767, 3869.1071784622486, 4145.213384566142]\n",
      "mean reward 3763.963238267007\n",
      "std of reward 1032.308659488299\n",
      "\n",
      "Task Ant-v2. Model trained over 8 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4537.715672233195, 4355.0986436673675, 4501.004384502603, 4220.521508910013, 4772.50131717345, 4874.2190212035075, 4559.385343060677, 4510.143583097197, 4555.50530807853, 4690.716486603, 4662.0606308899, 4715.4911224610405, 4430.404776034759, 4470.66023905262, 4299.746630923881, 4418.139558372059, 4499.633772024331, 4304.695211451973, 4512.874390875848, 4616.685141860083]\n",
      "mean reward 4525.360137123802\n",
      "std of reward 161.58241726234795\n",
      "\n",
      "Task Ant-v2. Model trained over 10 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4679.657739046505, 4350.738405008757, 4613.215441199063, 4732.616239482456, 4563.097381236131, 4626.997500002615, 4703.85758593694, 4609.060089463138, 4582.974440240637, 4632.998130257036, 4690.079669552485, 4323.171950914267, 4262.17638470485, 4506.6166812300235, 4561.45380141976, 4697.613947818456, 4923.384353251701, 4603.100674412379, 4543.592151206501, 4579.408787631299]\n",
      "mean reward 4589.290567700749\n",
      "std of reward 145.78803394050337\n",
      "\n",
      "Task Ant-v2. Model trained over 12 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4597.55187157863, 4694.931339331154, 4818.020104220168, 4627.104866718422, 4764.276408981437, 4541.607015424173, 4508.82366052208, 4669.379030515294, 4708.028727892079, 4757.883688056376, 4806.542516033688, 4690.481873564811, 4674.70229039546, 4716.7292153050175, 4779.2732583992565, 4729.438205342965, 4814.209777859108, 4656.364547180056, 4600.623276963784, 4385.855060082201]\n",
      "mean reward 4677.0913367183075\n",
      "std of reward 107.79882524962223\n",
      "\n",
      "Task Ant-v2. Model trained over 14 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4677.750755956063, 4698.011288282545, 4511.669369583281, 4764.716035696881, 4794.889760515419, 4799.085482636452, 4823.7318520147855, 4852.284298547072, 4838.921324137361, 4844.138918032557, 4793.777753499985, 4838.460189579685, 4948.042632751975, 4755.44614306661, 4713.65712328994, 4731.552064468706, 4802.1364181729505, 4786.836087968078, 4667.682024766422, 4669.00768118392]\n",
      "mean reward 4765.589860207535\n",
      "std of reward 90.89458546686951\n",
      "\n",
      "Task Ant-v2. Model trained over 16 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4811.862335295927, 4536.038932706459, 4853.893408665208, 4749.300208954347, 4752.020202377791, 4636.198872098912, 4673.094847187645, 4809.5317796094, 4810.499136483123, 4605.583227937012, 4729.666137026448, 4542.327573513732, 4693.327551429157, 4815.00208775805, 4418.615368742602, 4857.198925446335, 4749.780069946628, 4888.0417116923, 4709.581187523235, 4492.322458086549]\n",
      "mean reward 4706.694301124044\n",
      "std of reward 128.29559446174432\n",
      "\n",
      "Task Ant-v2. Model trained over 18 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4825.78329689694, 4740.5829076668815, 4666.461354137777, 4780.304269314478, 4803.010131986532, 4764.2555202605545, 4539.518011219481, 5016.526473967816, 4665.324999612984, 4766.50034927861, 4847.769833093745, 4773.81045323979, 4756.591383637209, 4676.808691583274, 4837.426251610093, 4753.881955282691, 4749.290582329304, 4905.223483940255, 4742.274909869648, 4739.573213784753]\n",
      "mean reward 4767.54590363564\n",
      "std of reward 95.08260837371859\n",
      "\n",
      "Task Ant-v2. Model trained over 20 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4769.569886380128, 4936.750227863473, 4648.78126897643, 4694.3699501247265, 4958.915611538071, 4800.243640188271, 4862.050861844043, 4919.0192687645185, 4986.115958383198, 4722.885970543998, 4820.704892230838, 4473.677357743709, 4975.706092756081, 4799.315382514127, 4942.940603817015, 4852.470756801435, 5033.607324482966, 4860.799633792337, 4576.504018757799, 4834.080724587739]\n",
      "mean reward 4823.425471604544\n",
      "std of reward 140.86990579231423\n",
      "\n",
      "Task Ant-v2. Model trained over 22 epochs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4811.1392015009405, 4842.785426472752, 4732.384017349824, 4899.231337242583, 4943.567872698886, 4910.753456463385, 4635.2080755943525, 4726.86481263996, 4710.309789909099, 4811.313275256068, 4840.381399999457, 4716.703100341105, 4833.561053051133, 4944.258177727164, 4710.168990640483, 4729.664801792437, 4879.008156384222, 4828.947256314086, 4778.085181730472, 4738.139356026361]\n",
      "mean reward 4801.123736956739\n",
      "std of reward 85.09212559749496\n",
      "\n",
      "Task Ant-v2. Model trained over 24 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4814.4619864233555, 4641.1742808575, 4772.5646372025, 4913.793527090415, 4696.5792815813975, 4814.267248798814, 4715.21307322137, 4824.160793052934, 4725.407780634386, 4717.457911559364, 4650.321304421889, 4652.743826176328, 4773.008129956686, 4641.67879795567, 4929.562559789614, 4808.967432302695, 4898.250663319033, 4704.474576209878, 4727.025456682457, 4775.774651061546]\n",
      "mean reward 4759.844395914892\n",
      "std of reward 86.42213676466058\n",
      "\n",
      "Task Ant-v2. Model trained over 26 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4821.847116453601, 4722.086543452951, 4749.473894687082, 4646.158039416901, 4897.505211386227, 4613.354466877887, 4945.143369033934, 4585.501987214765, 4708.6536007324685, 4835.9139738446265, 4612.10707597251, 4912.100401755687, 4820.56001015339, 4611.2083300900185, 4719.037894333784, 4608.296972839566, 4766.404067280395, 4723.326995083096, 4752.249966329097, 4660.370663163554]\n",
      "mean reward 4735.565029005078\n",
      "std of reward 106.491443490987\n",
      "\n",
      "Task Ant-v2. Model trained over 28 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4718.915872185289, 4621.390471110208, 4566.475766487453, 4617.2700755345295, 4926.837020803184, 4634.172756741837, 4802.110976105304, 4790.433803160149, 4845.841768790044, 4607.097157258357, 4641.977264026176, 4954.614360290928, 4835.369578732833, 4709.98506787381, 4793.66068397376, 4778.286943304309, 4771.879059087018, 4760.610106785336, 4791.283596633736, 4827.949697767499]\n",
      "mean reward 4749.808101332587\n",
      "std of reward 105.10759788032718\n",
      "\n",
      "Task Ant-v2. Model trained over 30 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [5054.439564898901, 4945.115344827266, 4857.28303984711, 4827.383843836084, 4757.946279122759, 4751.567685780064, 4859.460660865571, 4937.053493547891, 4933.87939345994, 4884.828872818277, 4967.068211581199, 4965.591793383921, 4792.995499526702, 4845.470449025656, 4886.833180822867, 4825.289587864137, 4737.482984724752, 4972.814775248445, 4883.853267817426, 4876.458603279481]\n",
      "mean reward 4878.140826613922\n",
      "std of reward 81.09922834336137\n",
      "\n",
      "Task Ant-v2. Model trained over 32 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4816.387647454083, 4987.449735567821, 4884.191097699169, 4706.800427638554, 4906.534445507609, 4947.1365084718645, 4730.4971756844625, 4864.9625859977, 2496.739182720051, 4711.862731933333, 4906.910585740904, 4907.6322979798715, 4801.243762935372, 4778.989561195013, 4722.601549533501, 4749.18095967331, 4988.533340020653, 4819.811013398727, 4866.521848805976, 4759.736546086673]\n",
      "mean reward 4717.686150202232\n",
      "std of reward 516.9386432182625\n",
      "\n",
      "Task Ant-v2. Model trained over 34 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4802.528898315261, 4710.16897261202, 4683.872880723909, 4974.98086953574, 4742.293572421098, 4882.549064537177, 4580.121133005598, 4567.665751517945, 4863.626048028059, 4558.91713762393, 4620.376107228237, 4683.646604587565, 4768.390688716447, 4845.08053644297, 4712.022494476412, 4735.450950711276, 4662.234485536631, 4869.914167015455, 4872.604265802527, 4877.992441009143]\n",
      "mean reward 4750.721853492369\n",
      "std of reward 117.0929191805919\n",
      "\n",
      "Task Ant-v2. Model trained over 36 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4763.19406143251, 4732.506277561426, 4803.42134898795, 4811.1571277443345, 4850.783716186998, 4813.840746925221, 4744.720578773593, 4744.193468762911, 4884.606462714755, 4811.283989201856, 4790.160244725315, 4895.020728855542, 4971.566634589535, 4737.613334496772, 4780.72399222313, 4721.819614679139, 4810.04291565017, 4995.246079684441, 5049.148880119714, 4938.028048099351]\n",
      "mean reward 4832.453912570732\n",
      "std of reward 92.05785046645613\n",
      "\n",
      "Task Ant-v2. Model trained over 38 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4609.250568636961, 4770.492116126866, 4669.786071550893, 4925.225548976149, 4839.530404170143, 4836.282155127035, 4811.438155161907, 4827.613380814354, 4915.41571091821, 4729.566922075538, 4777.738236580295, 4563.064287674434, 4956.825373518839, 4464.921816719339, 4708.994333398088, 4706.707691745164, 4822.030783939357, 4764.899675869407, 4873.658107395217, 4928.855046546901]\n",
      "mean reward 4775.114819347255\n",
      "std of reward 125.25961501267382\n",
      "\n",
      "Task Ant-v2. Model trained over 40 epochs:\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4747.36688917604, 4788.41111110607, 4810.1791895050455, 4708.141152763637, 4674.47173663763, 4715.703349563213, 4812.62351955119, 4891.138071230792, 4816.173081277042, 4846.086151064292, 4814.335149734844, 4973.868639438085, 4825.671137246803, 4708.16904048724, 4803.280003060074, 4888.314540916666, 4875.216407661912, 4517.09519650904, 4859.965556681282, 4666.579879130065]\n",
      "mean reward 4787.139490137048\n",
      "std of reward 99.06563763348079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance_means_over_epochs = []\n",
    "performance_stds_over_epochs = []\n",
    "\n",
    "for epoch_num in epoch_range:\n",
    "    model_name = \"BC_model_\" + TASK_multi_epoch + \"_epochs_\" + str(epoch_num) + \".h5\"\n",
    "    model_dir = TASK_multi_epoch + \"_epochs\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_dir, model_name)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Task {}. Model trained over {} epochs:\".format(TASK_multi_epoch, epoch_num))\n",
    "        ret_dict = load_test_model(TASK_multi_epoch, model_path)\n",
    "        performance_means_over_epochs.append( ret_dict[\"mean reward\"] )\n",
    "        performance_stds_over_epochs.append( ret_dict[\"std of reward\"] )\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + TASK_multi_epoch + \", trained over \" + str(epoch_num)\n",
    "              + \" epoches, doest not exist. Build and train it first.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(epoch_range, performance_means_over_epochs, \"o-\")\n",
    "plt.errorbar(epoch_range, performance_means_over_epochs, performance_stds_over_epochs,\n",
    "             color='r', linestyle=\"None\", marker='^')\n",
    "plt.title(\"BC Performance vs Number of Epochs - Task {}\".format(TASK_multi_epoch))\n",
    "plt.xlabel(\"number of epochs\")\n",
    "plt.ylabel(\"mean reward\")\n",
    "plt.savefig( os.path.join(DIRNAME_output, \"BC_Performance_vs_Epochs_\" + TASK_multi_epoch + \".png\") )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow_gpu-python3)",
   "language": "python",
   "name": "tensorflow_gpu-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
