{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TASK = \"Ant-v2\"\n",
    "# TASK = \"HalfCheetah-v2\"\n",
    "# TASK = \"Hopper-v2\"\n",
    "# TASK = \"Humanoid-v2\"\n",
    "# TASK = \"Reacher-v2\"\n",
    "# TASK = \"Walker2d-v2\"\n",
    "\n",
    "# TASK_LIST = [\"Ant-v2\", \"HalfCheetah-v2\", \"Hopper-v2\", \"Humanoid-v2\", \"Reacher-v2\", \"Walker2d-v2\"]\n",
    "TASK_LIST = [\"Ant-v2\", \"Humanoid-v2\"]\n",
    "\n",
    "DIRNAME_experts = \"experts\"\n",
    "DIRNAME_expert_data = \"expert_data\"\n",
    "DIRNAME_MODELS = \"BC_models_bonus\"\n",
    "DIRNAME_output = \"output\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4\n",
    "    Two new model:\n",
    "    1. Replace Activation ReLU by tanh\n",
    "    2. Add one more hidden layer and change the size of all hidden layer from (64,) to (128,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Ant-v2. Behavioral Cloning bonus.\n",
      "The shapes of training input and output: X:(20000, 111), Y:(20000, 8)\n",
      "Training model ...\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.0196\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.0072\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0051\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0040\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0033\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.0028\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0024\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0021\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0019\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0017\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0016\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0014\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0013\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0012\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0012\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0011\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.0010\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0010\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 9.3859e-04\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 9.2680e-04\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 8.3680e-04\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 7.8216e-04\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 8.1923e-04\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 7.5745e-04\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 7.4387e-04\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 7.2063e-04\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.8900e-04\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.8518e-04\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.5663e-04\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.3382e-04\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.2920e-04\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.4088e-04\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.1719e-04\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.9702e-04\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 5.6398e-04\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.6832e-04\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 5.3222e-04\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 5.5011e-04\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.1486e-04\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.4191e-04\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 5.2037e-04\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 5.2124e-04\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 4.7701e-04\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 4.6990e-04\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.7439e-04\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 4.6927e-04\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.7807e-04\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 4.4748e-04\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.6609e-04\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 4.4332e-04\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.9229e-04\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.5617e-04\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.1843e-04\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.6190e-04\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.0060e-04\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.9089e-04\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.1162e-04\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.7856e-04\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.2252e-04\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.0005e-04\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.8908e-04\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.7805e-04\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.7640e-04\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.0299e-04\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.8389e-04\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.9363e-04\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.4857e-04\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.7873e-04\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.6924e-04\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.5820e-04\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4661e-04\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4209e-04\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4905e-04\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.7420e-04\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.5759e-04\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4271e-04\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4433e-04\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.6250e-04\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.1540e-04\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.3764e-04\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.3174e-04\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.2830e-04\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.5874e-04\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.5574e-04\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.1036e-04\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.3879e-04\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 2.8471e-04\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4305e-04\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.1699e-04\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.1944e-04\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.1099e-04\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 2.8706e-04\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.2337e-04\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.0800e-04\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.0343e-04\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.1665e-04\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.0251e-04\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 2.8193e-04\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 2.8244e-04\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 3.5458e-04\n",
      "\n",
      "Task Humanoid-v2. Behavioral Cloning bonus.\n",
      "The shapes of training input and output: X:(20000, 376), Y:(20000, 17)\n",
      "Training model ...\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 6.3738\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.4860\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.3453\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.2675\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.2381\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.1927\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1981\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1627\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.1564\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1374\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1339\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1206\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.1199\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1103\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.1063\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.1052\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.1009\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0937\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0950\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0912\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0844\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0816\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0777\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0753\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0707\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0704\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0668\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0660\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0656\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0607\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0604\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0607\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0574\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0549\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0544\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0537\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0525\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0512\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0503\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0487\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0490\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0476\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0466\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0461\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0453\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0433\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0434\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0422\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0418\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 1s 25us/step - loss: 0.0409\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0411\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0406\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0394\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0393\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0380\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0377\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0381\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0366\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0373\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0362\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0354\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0350\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0341\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0344\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0342\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0331\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0336\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0329\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0326\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0328\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0325\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0318\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0318\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0310\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0308\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0309\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0299\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0304\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0300\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0307\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0300\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0293\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0297\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0291\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0289\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0288\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 1s 25us/step - loss: 0.0290\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0280\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0286\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0282\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0275\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0280\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0278\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0276\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0270\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0272\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 0.0269\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0267\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0263\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 0.0261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_train_save_model(X_train, Y_train, model_path, batch_size=BATCH_SIZE, epochs=EPOCHS):\n",
    "    \n",
    "    print(\"The shapes of training input and output: X:{}, Y:{}\".format(X_train.shape, Y_train.shape))\n",
    "    sample_size = X_train.shape[0]\n",
    "    input_size = X_train.shape[-1]\n",
    "    output_size = Y_train.shape[-1]\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Hidden layer 1: input -> output (64,)\n",
    "    model.add( tf.keras.layers.Dense(128, input_dim=input_size) )\n",
    "    model.add( tf.keras.layers.Activation(\"relu\") )\n",
    "    \n",
    "    # Hidden layer 2: output (64,) -> output (64,)\n",
    "    model.add( tf.keras.layers.Dense(128) )\n",
    "    model.add( tf.keras.layers.Activation(\"relu\") )\n",
    "    \n",
    "    # Hidden layer 3: output (64,) -> output (64,)\n",
    "    model.add( tf.keras.layers.Dense(128) )\n",
    "    model.add( tf.keras.layers.Activation(\"relu\") )\n",
    "    \n",
    "    # Hidden layer 3: output (64,) -> output\n",
    "    model.add( tf.keras.layers.Dense(output_size) )\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=\"Adam\")\n",
    "    print(\"Training model ...\")\n",
    "    model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=epochs, verbose=1)\n",
    "    \n",
    "    model_dir = os.path.dirname(model_path)\n",
    "    if not os.path.isdir( model_dir ):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    model.save(model_path)\n",
    "\n",
    "    \n",
    "for task in TASK_LIST:\n",
    "    model_name = \"BC_model_\" + task + \".h5\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Task {}. Behavioral Cloning bonus.\".format(task))\n",
    "        datafile = os.path.join(DIRNAME_expert_data, task + \".pkl\")\n",
    "        \n",
    "        with open(datafile, 'rb') as f:\n",
    "            expert_data = pickle.load(f)\n",
    "\n",
    "        X_train = expert_data[\"observations\"]\n",
    "        Y_train = np.squeeze( expert_data[\"actions\"] )\n",
    "        \n",
    "        build_train_save_model(X_train, Y_train, model_path)\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + task + \" exists in the directory \" + DIRNAME_MODELS + '.')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Ant-v2. Behavioral Cloning bonus\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [4914.105459113547, 4874.280496122403, 4649.264697694852, 4735.383648726234, 4743.513090966455, 4937.337810790904, 4874.82003013037, 4723.360965866456, 4897.6961228759465, 4661.103690603662, 4793.506741975252, 4770.019226850782, 4749.182726033616, 4847.972421813718, 4912.251795760525, 4747.5160645845435, 4579.10091213297, 4836.944451576873, 4857.078340684965, 4871.440878757997]\n",
      "mean reward 4798.793978653104\n",
      "std of reward 96.81645668813218\n",
      "\n",
      "Task Humanoid-v2. Behavioral Cloning bonus\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "rewards [500.848929324218, 334.91085396181285, 796.1780510396505, 907.2280462931468, 971.9283450228735, 1169.3143984495196, 2098.242358980576, 434.47818631897417, 475.5252178513815, 1236.57053236883, 1303.3296309913694, 475.15606007091156, 865.38951272692, 550.2405603196801, 1585.2528447427394, 1032.712694657904, 657.0792660233391, 701.1931037761153, 844.8299499750945, 768.9498085023198]\n",
      "mean reward 885.4679175698687\n",
      "std of reward 423.1752667644132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_test_model(task, model_path):\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    envname = task\n",
    "    env = gym.make(envname)\n",
    "    max_steps = env.spec.timestep_limit\n",
    "    num_rollouts = 20\n",
    "    \n",
    "    rewards = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(num_rollouts):\n",
    "        print(\"iter\", i)\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model.predict(obs.reshape(1, -1), verbose=0)\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            if False:\n",
    "                env.render()\n",
    "#             if steps % 100 == 0:\n",
    "#                 print(\"{}/{}\".format(steps, max_steps))\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        rewards.append(total_reward)\n",
    "        \n",
    "    mean_reward, std_reward = np.mean(rewards), np.std(rewards)\n",
    "    print(\"rewards\", rewards)\n",
    "    print(\"mean reward\", mean_reward)\n",
    "    print(\"std of reward\", std_reward)\n",
    "    \n",
    "    ret_dict = {\"rewards\": rewards, \"mean reward\": mean_reward, \"std of reward\": std_reward}\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "for task in TASK_LIST:\n",
    "    model_name = \"BC_model_\" + task + \".h5\"\n",
    "    model_path = os.path.join(DIRNAME_MODELS, model_name)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Task {}. Behavioral Cloning bonus\".format(task))\n",
    "        load_test_model(task, model_path)\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"Model of \" + task + \" doest not exist. Build and train it first.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tensorflow_gpu-python3)",
   "language": "python",
   "name": "tensorflow_gpu-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
